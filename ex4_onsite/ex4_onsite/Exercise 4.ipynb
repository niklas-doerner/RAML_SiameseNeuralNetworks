{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d989a94",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91481d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71801858",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Contents\n",
    "- Stochastic Gradient Descent\n",
    "- PyTorch: Coding Example\n",
    "- Training a Network: Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f1f23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db59d9e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Gradient Descent:** $\\theta(k+1) = \\theta(k) - \\tau * \\nabla E(\\theta(k))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964aa9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Problem:** Expensive for a lot of training examples e.g. $E \\in \\mathbb{R}^{1,000,000 \\times 10}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf0b33e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Solution:** Approximate gradient vector by only using a few samples at a time (mini-batches)\n",
    "- This is what we call **Stochastic Gradient Descent**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630a3a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Practical Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf0be2f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (851538047.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    # do gradient descent step with suitable step size only using loss computed on sampled in minibatch\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    # shuffle training data\n",
    "    for i in range(0, total_number_of_training_examples, minibatch_size):\n",
    "        # take chunk i:i+minibatch_size out of (shuffeled) training data\n",
    "        # do gradient descent step with suitable step size only using loss computed on sampled in minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02663c6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTorch: Coding Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee424c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Deep Learning framework providing powerful tools for simple and efficient implementations of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bf6de4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d8201",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tensors\n",
    "- Basic building block\n",
    "- Similar to what you did in `toolbox.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8712118a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(np.array([[1., 2.], [3., 4.]]))\n",
    "b = torch.ones(2, 2)\n",
    "c = torch.empty(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2f32a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation in PyTorch\n",
    "\n",
    "- Uses gradient taping (same as you did in the last exercise)\n",
    "- Same attributes and functions (`grad`, `grad_fn`, `.backward()`, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4053e0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.) None\n",
      "<AddBackward0 object at 0x7fa13819d5b0> <MulBackward0 object at 0x7fa138193340>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nd/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975993/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1., requires_grad=True)\n",
    "b = torch.tensor(2.)\n",
    "\n",
    "c = a + b\n",
    "d = c + a\n",
    "d = d * d\n",
    "\n",
    "d.backward()\n",
    "\n",
    "print(a.grad, b.grad)\n",
    "print(c.grad_fn, d.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f6133",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `torch.no_grad()` \n",
    "\n",
    "- Used during inference (feeding data through network to get prediction)\n",
    "- Causes computation graph not to be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4498b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GPU Support (CUDA)\n",
    "- GPUs offer high amount of parallelization & efficient calculation of simple (mathmatical) operations\n",
    "- All major Deep Learning frameworks offer possibility of utilizing GPUs\n",
    "- PyTorch: \n",
    "    - `.cuda()` moves Tensor to GPU\n",
    "    - `.device` tells which device Tensor is on\n",
    "    \n",
    "**Disclaimer:** If you don't have a GPU, try Google Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca1e327",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2.\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.)\n",
    "print(a.device)\n",
    "\n",
    "a = a.cuda()\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529133df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `torch.utils.data.Dataset`\n",
    "- Provides some handy tools to make treatment of data very easy\n",
    "- Base class overloads functions ``__len__`` and ``__getitem__`` (allow easy access to data contained in the set)\n",
    "- `torchvision.datasets` provides popular public datasets (e.g. MNIST dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c6c9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "train_set = MNIST('data', download=True, transform=transforms.ToTensor())\n",
    "val_set = MNIST('data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "print(train_set)\n",
    "print(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6763d9dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m el \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_set\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElement type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m; Shape of element: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m; Label: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(el) ,el[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, el[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(el[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "el = train_set[0]\n",
    "print('Element type: {}; Shape of element: {}; Label: {}'.format(type(el) ,el[0].shape, el[1]))\n",
    "\n",
    "plt.imshow(el[0][0], cmap='gray', vmin=0., vmax=1.)\n",
    "plt.title('Label: {}'.format(el[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c5e82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `torch.utils.data.DataLoader`\n",
    "- Efficiently load data to processing unit.\n",
    "- Takes care of minibatching (only have to provide dataset & define batch size)\n",
    "- Additionally, may specify further arguments (`shuffeling`, `num_workers`, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a038a874",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 3\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_set\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\u001b[38;5;241m.\u001b[39mnext()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=4, num_workers=4, shuffle=True)\n",
    "\n",
    "batch = iter(train_loader).next()\n",
    "\n",
    "data, labels = batch[0], batch[1]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(data[i, 0], cmap='gray', vmin=0., vmax=1.)\n",
    "    plt.title('Label: {}'.format(labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54491869",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `torch.nn`\n",
    "\n",
    "- Provides a broad variety of pre-implemented tools & layers you can use in neural networks\n",
    "- ``Module`` in ``torch.nn`` serves as base class for neural networks & their layers\n",
    "- For defining network, have to inherit from ``torch.nn.Module`` and define the ``forward`` function\n",
    "- `torch.nn.Sequential` = condense multiple layers\n",
    "\n",
    "**NOTE:** not sufficient to store layers in list - will be not registered as submodules of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c71634",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=28*28, out_features=32)\n",
    "        self.layer2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.layer4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "    \n",
    "network = FullyConnectedNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2888fbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Losses & Optimizers\n",
    "- PyTorch offers a lot of pre-implemented losses and optimizers\n",
    "- Optimizers are directly linked with the weights of a network.\n",
    "- Have a look at the documentation and see what you already know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33159177",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91df19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters\n",
    "- Can access learnable parameters of a network by calling its `parameters` function\n",
    "- `state_dict` function: also returns buffers etc.  (used when saving models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3174f26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0256,  0.0100,  0.0276,  ...,  0.0113, -0.0242,  0.0037],\n",
       "         [ 0.0259,  0.0284, -0.0182,  ..., -0.0300,  0.0345,  0.0276],\n",
       "         [-0.0272,  0.0260,  0.0024,  ...,  0.0119, -0.0282, -0.0070],\n",
       "         ...,\n",
       "         [-0.0224, -0.0237,  0.0078,  ...,  0.0120, -0.0120,  0.0315],\n",
       "         [-0.0100, -0.0035, -0.0057,  ...,  0.0164,  0.0320,  0.0219],\n",
       "         [-0.0080,  0.0014, -0.0079,  ...,  0.0094,  0.0277, -0.0294]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0101, -0.0337, -0.0162,  0.0327,  0.0194, -0.0230, -0.0057,  0.0243,\n",
       "          0.0219, -0.0137, -0.0185, -0.0338,  0.0176,  0.0338,  0.0080,  0.0281,\n",
       "          0.0175, -0.0252,  0.0034,  0.0079, -0.0212,  0.0150,  0.0261, -0.0084,\n",
       "         -0.0111, -0.0178,  0.0324, -0.0014,  0.0191, -0.0295,  0.0350,  0.0245],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0237,  0.0200, -0.1440,  ...,  0.1325, -0.1747,  0.0891],\n",
       "         [ 0.0877, -0.0413,  0.0057,  ..., -0.0375, -0.1395, -0.1714],\n",
       "         [ 0.0717, -0.1198, -0.1639,  ..., -0.1015,  0.1143, -0.0449],\n",
       "         ...,\n",
       "         [ 0.0709,  0.0973,  0.1271,  ...,  0.0944, -0.1368, -0.0454],\n",
       "         [ 0.1310, -0.0796,  0.0453,  ..., -0.1161, -0.1325,  0.0747],\n",
       "         [-0.1266,  0.1122,  0.0281,  ..., -0.1361, -0.0986, -0.0473]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0843,  0.1033, -0.1502,  0.1036,  0.1603, -0.1547,  0.1041,  0.0048,\n",
       "         -0.1331,  0.1005,  0.1112, -0.0076,  0.0484,  0.1617, -0.1457, -0.0846,\n",
       "         -0.0796,  0.0666, -0.0571, -0.0463, -0.0665,  0.0647, -0.1594,  0.1329,\n",
       "         -0.0553,  0.0660, -0.1101,  0.1400,  0.1441, -0.1598,  0.0221,  0.0531],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0116, -0.1255, -0.1042,  0.0006, -0.1404,  0.0908, -0.1120,  0.1337,\n",
       "           0.1008,  0.1366,  0.1676,  0.1727,  0.0525,  0.1706,  0.1632, -0.0788,\n",
       "          -0.0772,  0.1108, -0.0072,  0.0716,  0.0670, -0.0762, -0.1488, -0.0101,\n",
       "           0.0862, -0.1105, -0.0344, -0.0773,  0.1269, -0.0129,  0.0050, -0.0513],\n",
       "         [ 0.0676, -0.1417,  0.0402, -0.1012, -0.0869, -0.1238, -0.1743, -0.0481,\n",
       "          -0.1308,  0.0929,  0.1650,  0.0484, -0.1128,  0.1036,  0.0516, -0.0469,\n",
       "           0.1751, -0.0438,  0.0090, -0.0524, -0.1201,  0.0057,  0.1196, -0.0436,\n",
       "           0.1143, -0.0008, -0.0977,  0.0790, -0.1262,  0.0614, -0.0115,  0.0264],\n",
       "         [ 0.1417,  0.0503, -0.1017,  0.1135, -0.0097,  0.0611, -0.1503,  0.0834,\n",
       "           0.1187,  0.0788,  0.0272, -0.0771, -0.0059, -0.1623, -0.0278,  0.1748,\n",
       "          -0.1211,  0.0002, -0.0081,  0.0669,  0.1297, -0.0540, -0.0454, -0.0103,\n",
       "          -0.0211, -0.0026, -0.1503,  0.1748,  0.0031,  0.0705, -0.0850,  0.0679],\n",
       "         [-0.1732,  0.0587,  0.1404, -0.1692, -0.1200, -0.0728, -0.0327, -0.1172,\n",
       "          -0.0636, -0.0713, -0.1375, -0.1106,  0.0268,  0.1088, -0.1068, -0.0942,\n",
       "           0.0432, -0.1229,  0.0473,  0.0846,  0.0059,  0.1156, -0.1111,  0.0201,\n",
       "          -0.0415, -0.0842, -0.0498, -0.0514, -0.0457,  0.1156, -0.1269,  0.0600],\n",
       "         [ 0.0853,  0.1548,  0.1018, -0.0494,  0.0131, -0.1247, -0.1215, -0.1177,\n",
       "           0.0710, -0.1702, -0.0180, -0.0246, -0.1586,  0.1265, -0.0672,  0.0972,\n",
       "          -0.1439, -0.1346,  0.0847,  0.1049, -0.0521, -0.1239, -0.0936, -0.1310,\n",
       "          -0.1226,  0.1373, -0.1214,  0.0076,  0.1581,  0.0021,  0.1067,  0.0663],\n",
       "         [ 0.1406, -0.0825, -0.1334, -0.0157,  0.0257,  0.0154,  0.0873,  0.0153,\n",
       "          -0.1070, -0.1758,  0.1444,  0.0903,  0.0120, -0.0994,  0.0766, -0.0744,\n",
       "          -0.0501, -0.1265, -0.1609, -0.0195,  0.0110,  0.1643, -0.0117,  0.1454,\n",
       "          -0.1166, -0.1635, -0.0093,  0.1684,  0.1186, -0.1015,  0.0732,  0.0866],\n",
       "         [-0.0086, -0.0924, -0.0093, -0.1327, -0.1300, -0.0741,  0.1336, -0.1593,\n",
       "          -0.0487, -0.0513, -0.0338, -0.0259, -0.1303, -0.1122, -0.0101, -0.0003,\n",
       "          -0.1153,  0.0249,  0.0943, -0.0262, -0.0644,  0.1060, -0.0428,  0.0765,\n",
       "           0.1098, -0.1764,  0.1505, -0.0420, -0.0127, -0.1483,  0.0093,  0.0248],\n",
       "         [-0.0450, -0.1703,  0.0586, -0.1304, -0.0630, -0.0226, -0.0911, -0.0601,\n",
       "          -0.0540, -0.0882,  0.0220, -0.1247, -0.1527,  0.0607,  0.0020,  0.0788,\n",
       "           0.1439,  0.0789,  0.0002, -0.0147, -0.0055,  0.1075, -0.1694,  0.1101,\n",
       "          -0.0222, -0.1534, -0.0480,  0.0866,  0.0478,  0.0724,  0.0734, -0.0344],\n",
       "         [-0.1491, -0.1362, -0.1005,  0.0924, -0.1655,  0.1091,  0.1149, -0.0025,\n",
       "          -0.0038,  0.1199,  0.1207, -0.0545,  0.0126, -0.1182, -0.0225,  0.0782,\n",
       "           0.0616,  0.0714, -0.1668, -0.1717, -0.1750,  0.1505, -0.0710, -0.0734,\n",
       "           0.1177, -0.1169, -0.1410,  0.0653, -0.1097,  0.0271,  0.1458, -0.0629],\n",
       "         [-0.0542, -0.0303, -0.0585, -0.0873, -0.0540, -0.1602, -0.1442, -0.1712,\n",
       "          -0.1321,  0.1398, -0.0674,  0.0266, -0.1661, -0.1357,  0.0139, -0.1246,\n",
       "          -0.1025,  0.1450, -0.1601, -0.0471,  0.1197,  0.0629, -0.0191, -0.1289,\n",
       "          -0.0807, -0.0603, -0.0161, -0.1077,  0.1580,  0.0839,  0.1178,  0.1327]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0481, -0.1662, -0.1180,  0.1585,  0.0678, -0.0968, -0.0830, -0.1073,\n",
       "          0.0820, -0.0271], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52479eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[ 0.0256,  0.0100,  0.0276,  ...,  0.0113, -0.0242,  0.0037],\n",
       "                      [ 0.0259,  0.0284, -0.0182,  ..., -0.0300,  0.0345,  0.0276],\n",
       "                      [-0.0272,  0.0260,  0.0024,  ...,  0.0119, -0.0282, -0.0070],\n",
       "                      ...,\n",
       "                      [-0.0224, -0.0237,  0.0078,  ...,  0.0120, -0.0120,  0.0315],\n",
       "                      [-0.0100, -0.0035, -0.0057,  ...,  0.0164,  0.0320,  0.0219],\n",
       "                      [-0.0080,  0.0014, -0.0079,  ...,  0.0094,  0.0277, -0.0294]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([-0.0101, -0.0337, -0.0162,  0.0327,  0.0194, -0.0230, -0.0057,  0.0243,\n",
       "                       0.0219, -0.0137, -0.0185, -0.0338,  0.0176,  0.0338,  0.0080,  0.0281,\n",
       "                       0.0175, -0.0252,  0.0034,  0.0079, -0.0212,  0.0150,  0.0261, -0.0084,\n",
       "                      -0.0111, -0.0178,  0.0324, -0.0014,  0.0191, -0.0295,  0.0350,  0.0245])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[-0.0237,  0.0200, -0.1440,  ...,  0.1325, -0.1747,  0.0891],\n",
       "                      [ 0.0877, -0.0413,  0.0057,  ..., -0.0375, -0.1395, -0.1714],\n",
       "                      [ 0.0717, -0.1198, -0.1639,  ..., -0.1015,  0.1143, -0.0449],\n",
       "                      ...,\n",
       "                      [ 0.0709,  0.0973,  0.1271,  ...,  0.0944, -0.1368, -0.0454],\n",
       "                      [ 0.1310, -0.0796,  0.0453,  ..., -0.1161, -0.1325,  0.0747],\n",
       "                      [-0.1266,  0.1122,  0.0281,  ..., -0.1361, -0.0986, -0.0473]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.0843,  0.1033, -0.1502,  0.1036,  0.1603, -0.1547,  0.1041,  0.0048,\n",
       "                      -0.1331,  0.1005,  0.1112, -0.0076,  0.0484,  0.1617, -0.1457, -0.0846,\n",
       "                      -0.0796,  0.0666, -0.0571, -0.0463, -0.0665,  0.0647, -0.1594,  0.1329,\n",
       "                      -0.0553,  0.0660, -0.1101,  0.1400,  0.1441, -0.1598,  0.0221,  0.0531])),\n",
       "             ('layer5.weight',\n",
       "              tensor([[-0.0116, -0.1255, -0.1042,  0.0006, -0.1404,  0.0908, -0.1120,  0.1337,\n",
       "                        0.1008,  0.1366,  0.1676,  0.1727,  0.0525,  0.1706,  0.1632, -0.0788,\n",
       "                       -0.0772,  0.1108, -0.0072,  0.0716,  0.0670, -0.0762, -0.1488, -0.0101,\n",
       "                        0.0862, -0.1105, -0.0344, -0.0773,  0.1269, -0.0129,  0.0050, -0.0513],\n",
       "                      [ 0.0676, -0.1417,  0.0402, -0.1012, -0.0869, -0.1238, -0.1743, -0.0481,\n",
       "                       -0.1308,  0.0929,  0.1650,  0.0484, -0.1128,  0.1036,  0.0516, -0.0469,\n",
       "                        0.1751, -0.0438,  0.0090, -0.0524, -0.1201,  0.0057,  0.1196, -0.0436,\n",
       "                        0.1143, -0.0008, -0.0977,  0.0790, -0.1262,  0.0614, -0.0115,  0.0264],\n",
       "                      [ 0.1417,  0.0503, -0.1017,  0.1135, -0.0097,  0.0611, -0.1503,  0.0834,\n",
       "                        0.1187,  0.0788,  0.0272, -0.0771, -0.0059, -0.1623, -0.0278,  0.1748,\n",
       "                       -0.1211,  0.0002, -0.0081,  0.0669,  0.1297, -0.0540, -0.0454, -0.0103,\n",
       "                       -0.0211, -0.0026, -0.1503,  0.1748,  0.0031,  0.0705, -0.0850,  0.0679],\n",
       "                      [-0.1732,  0.0587,  0.1404, -0.1692, -0.1200, -0.0728, -0.0327, -0.1172,\n",
       "                       -0.0636, -0.0713, -0.1375, -0.1106,  0.0268,  0.1088, -0.1068, -0.0942,\n",
       "                        0.0432, -0.1229,  0.0473,  0.0846,  0.0059,  0.1156, -0.1111,  0.0201,\n",
       "                       -0.0415, -0.0842, -0.0498, -0.0514, -0.0457,  0.1156, -0.1269,  0.0600],\n",
       "                      [ 0.0853,  0.1548,  0.1018, -0.0494,  0.0131, -0.1247, -0.1215, -0.1177,\n",
       "                        0.0710, -0.1702, -0.0180, -0.0246, -0.1586,  0.1265, -0.0672,  0.0972,\n",
       "                       -0.1439, -0.1346,  0.0847,  0.1049, -0.0521, -0.1239, -0.0936, -0.1310,\n",
       "                       -0.1226,  0.1373, -0.1214,  0.0076,  0.1581,  0.0021,  0.1067,  0.0663],\n",
       "                      [ 0.1406, -0.0825, -0.1334, -0.0157,  0.0257,  0.0154,  0.0873,  0.0153,\n",
       "                       -0.1070, -0.1758,  0.1444,  0.0903,  0.0120, -0.0994,  0.0766, -0.0744,\n",
       "                       -0.0501, -0.1265, -0.1609, -0.0195,  0.0110,  0.1643, -0.0117,  0.1454,\n",
       "                       -0.1166, -0.1635, -0.0093,  0.1684,  0.1186, -0.1015,  0.0732,  0.0866],\n",
       "                      [-0.0086, -0.0924, -0.0093, -0.1327, -0.1300, -0.0741,  0.1336, -0.1593,\n",
       "                       -0.0487, -0.0513, -0.0338, -0.0259, -0.1303, -0.1122, -0.0101, -0.0003,\n",
       "                       -0.1153,  0.0249,  0.0943, -0.0262, -0.0644,  0.1060, -0.0428,  0.0765,\n",
       "                        0.1098, -0.1764,  0.1505, -0.0420, -0.0127, -0.1483,  0.0093,  0.0248],\n",
       "                      [-0.0450, -0.1703,  0.0586, -0.1304, -0.0630, -0.0226, -0.0911, -0.0601,\n",
       "                       -0.0540, -0.0882,  0.0220, -0.1247, -0.1527,  0.0607,  0.0020,  0.0788,\n",
       "                        0.1439,  0.0789,  0.0002, -0.0147, -0.0055,  0.1075, -0.1694,  0.1101,\n",
       "                       -0.0222, -0.1534, -0.0480,  0.0866,  0.0478,  0.0724,  0.0734, -0.0344],\n",
       "                      [-0.1491, -0.1362, -0.1005,  0.0924, -0.1655,  0.1091,  0.1149, -0.0025,\n",
       "                       -0.0038,  0.1199,  0.1207, -0.0545,  0.0126, -0.1182, -0.0225,  0.0782,\n",
       "                        0.0616,  0.0714, -0.1668, -0.1717, -0.1750,  0.1505, -0.0710, -0.0734,\n",
       "                        0.1177, -0.1169, -0.1410,  0.0653, -0.1097,  0.0271,  0.1458, -0.0629],\n",
       "                      [-0.0542, -0.0303, -0.0585, -0.0873, -0.0540, -0.1602, -0.1442, -0.1712,\n",
       "                       -0.1321,  0.1398, -0.0674,  0.0266, -0.1661, -0.1357,  0.0139, -0.1246,\n",
       "                       -0.1025,  0.1450, -0.1601, -0.0471,  0.1197,  0.0629, -0.0191, -0.1289,\n",
       "                       -0.0807, -0.0603, -0.0161, -0.1077,  0.1580,  0.0839,  0.1178,  0.1327]])),\n",
       "             ('layer5.bias',\n",
       "              tensor([-0.0481, -0.1662, -0.1180,  0.1585,  0.0678, -0.0968, -0.0830, -0.1073,\n",
       "                       0.0820, -0.0271]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e5527",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a Network: Coding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7eac2c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_set\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_loader = DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=100, shuffle=False)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for e in range(epochs):\n",
    "    print('Epoch {} of {}'.format(e, epochs))\n",
    "\n",
    "    # Training\n",
    "    train_loss = 0.\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        y_pred = network.forward(x)\n",
    "        batch_loss = loss_fun(y_pred, y)\n",
    "        train_loss += batch_loss\n",
    "        network.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"Batch: {}/{}; Loss: {}\".format(i, len(train_loader), batch_loss))\n",
    "\n",
    "    # Inference\n",
    "    val_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(val_loader):\n",
    "            y_pred = network.forward(x)\n",
    "            val_loss += loss_fun(y_pred, y)\n",
    "\n",
    "    print(\"Epoch: {}/{}; Training loss: {}; Validation loss {}\".format(e, epochs, train_loss, val_loss))\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end - start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nFinal time elapsed: {:0>2}:{:0>2}:{:05.2f}\\n\".format(int(hours), int(minutes), seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b21943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651b189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806d180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d851d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd716be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fadc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
