{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ea3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bd968",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396fd9e",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Generalization techniques\n",
    "- Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adde096",
   "metadata": {},
   "source": [
    "## Generalization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a68e7",
   "metadata": {},
   "source": [
    "**Goal**: Increase network's performance on unseen data and avoid overfitting on training data (**function approximation**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9719511",
   "metadata": {},
   "source": [
    "You have seen five techniques:\n",
    "1. Early Stopping\n",
    "2. Data Augmentation\n",
    "3. Regularization\n",
    "4. Ensemble learning\n",
    "5. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fe109",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "= Stop when reaching a plateau and/ or witnessing increase in validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c78ca8",
   "metadata": {},
   "source": [
    "**Python implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ec8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e2e29",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "= Artifically increase the amount of training data by using existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d2bdb",
   "metadata": {},
   "source": [
    "- Simple techniques: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1456f5",
   "metadata": {},
   "source": [
    "<img src=\"augmentation_simple.jpg\" alt=\"Drawing\" style=\"width: 650px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6bec7",
   "metadata": {},
   "source": [
    "- More advanced techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94e24b",
   "metadata": {},
   "source": [
    "<img src=\"augmentation_advanced.jpg\" alt=\"Drawing\" style=\"width: 650px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68a07",
   "metadata": {},
   "source": [
    "**PyTorch Implementation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('giraffe.png')\n",
    "\n",
    "## See for more examples: \n",
    "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html\n",
    "flip = transforms.RandomHorizontalFlip(p=1)\n",
    "jitter = transforms.ColorJitter(brightness=.5, hue=.3)\n",
    "invert = transforms.RandomInvert(p=1)\n",
    "\n",
    "# apply above defined transform to input image\n",
    "img_list = [image]\n",
    "img_list.append(flip(img))\n",
    "img_list.append(jitter(img))\n",
    "img_list.append(invert(img))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=len(img_list), figsize=[8,8])\n",
    "                       \n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(img_list[i])\n",
    "    axi.set_yticklabels([])\n",
    "    axi.set_xticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5ff79",
   "metadata": {},
   "source": [
    "### Regularization \n",
    "= Bound or penalize your weights, e.g. by a quadratic penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d08ca7",
   "metadata": {},
   "source": [
    "- **Popular approach:** weight decay\n",
    "\n",
    "$$ E(\\theta) = \\sum_j{\\lVert \\mathcal{N}(x_j, \\theta) -y_j  \\rVert} + \\gamma \\lVert \\theta \\rVert ^ 2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d7bab",
   "metadata": {},
   "source": [
    "**PyTorch Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1043caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d4a1f",
   "metadata": {},
   "source": [
    "### Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17a8f5",
   "metadata": {},
   "source": [
    "= average results of different classifiers (different training algorithms, initializations, loss functions, or even different architectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5569e5",
   "metadata": {},
   "source": [
    "**Idea:** “Wisdom of the crowds”\n",
    "- A single individual cannot know everything\n",
    "- But together, a group of individuals knows a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954b5d6",
   "metadata": {},
   "source": [
    "**Prerequisite:** Independent learners!\n",
    "- If errors have little correlation, your results will improve! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bceea",
   "metadata": {},
   "source": [
    "**PyTorch Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layers = nn.Sequential(nn.Linear(10, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 10, bias=False)\n",
    "                                   )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layer = nn.Linear(10, 10, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class EnsembleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(20, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 10, bias=False),\n",
    "                                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "nn = DeepNet()\n",
    "linclf = LinearNet()\n",
    "    \n",
    "nn_output = nn.forward(x)\n",
    "linclf_output = linclf.foward(x)\n",
    "\n",
    "combined_output = \n",
    "    \n",
    "nn_ensemble = \n",
    "final_output = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a16ef",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "= Randomly set neurons to zero (\"turn off\") during training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbc473",
   "metadata": {},
   "source": [
    "**Intuition:**\n",
    "- learn redundant representations (learn to make right prediction even if not all features are present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc6d1e",
   "metadata": {},
   "source": [
    "**PyTorch Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNetDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layers = nn.Sequential(nn.Linear(10, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 100, bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(100, 10, bias=False)\n",
    "                                   )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24f376",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3acd8",
   "metadata": {},
   "source": [
    "### Four Outcomes of a Classification\n",
    "\n",
    "Given a binary prediction example (1/0):\n",
    "\n",
    "- **True Positive (TP)**: the prediction and ground truth label are both 1.\n",
    "- **False Positive (FP)**: the predicition is falsely 1, even though the ground truth is 0.\n",
    "- **True Negative (TN)**: the predicition is falsely 0, even though the ground truth label is of label is 1.\n",
    "- **False Negative (FN)**: the prediction and ground truth label are both 0.\n",
    "\n",
    "**For a multiclass problem:** can be calculated per class (1 = class of interest, 0 = all other classes). TP, FP, TN and FN would need to be calculated for all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db915c",
   "metadata": {},
   "source": [
    "<img src=\"binary_confusion.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9dfcf",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff752158",
   "metadata": {},
   "source": [
    "= Fraction of instances correctly predicted out of all instances in your dataset:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{FP} + \\text{TN} + \\text{FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8ca0e",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "= Fraction of instances which were correctly predicted to be positive out of all instances which were predicted as positive:\n",
    "\n",
    "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6979c",
   "metadata": {},
   "source": [
    "### Recall (sensitivity)\n",
    "\n",
    "= Fraction of instances which were correclty predicted to be positive out of all ground truth positive instances:\n",
    "\n",
    "$$\\text{recall} =\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46413614",
   "metadata": {},
   "source": [
    "### Specitivity\n",
    "\n",
    "= Fraction of instances which were correclty predicted to be negative out of all ground truth negative instances:\n",
    "\n",
    "\n",
    "$$\\text{specitivity} =\\frac{\\text{TN}}{\\text{TN} + \\text{FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81205fbd",
   "metadata": {},
   "source": [
    "### F1-score\n",
    "\n",
    "= Combines both recall and precision into one measure (harmonic mean):\n",
    "\n",
    "$$\\text{F1-score} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41cb80",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb768a7",
   "metadata": {},
   "source": [
    "<img src=\"multi_confusion.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2b984",
   "metadata": {},
   "source": [
    "**Question:** Decide for the following use cases which measure (recall, precision or F1-score) might be more relevant to optimise on:\n",
    "\n",
    "- Diagnosis of Cancer\n",
    "- Spam Filtering\n",
    "- Marketing Calls for Potential Customers\n",
    "- Pedestrian Detection during Autonomous Driving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600aaa9",
   "metadata": {},
   "source": [
    "**Take-Home Assignment:** Implement Accuracy, Recall, Precision, Sensitivity and F1-Score on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_tn_fn_fp(y_act, y_pred):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def compute_metrics(actual, predicted):\n",
    "    # calculate the number of tp, fp, tn, fn\n",
    "    tp, tn, fp, fn = compute_tp_tn_fn_fp(actual, predicted)\n",
    "    # calculate the precision value (hint: multiply by 100 to get nice percentage values)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    print('Accuracy: {}%; Precision: {}%; Recall: {}%; Sensitivity: {}%; F1-Score: {}%'.format(prec, prec, rec, sens, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [1, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n",
    "predictions = [1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "compute_metrics(ground_truth, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
